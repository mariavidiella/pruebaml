{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mapie.metrics import regression_coverage_score, regression_coverage_score_v2, regression_mean_width_score\n",
    "from mapie.regression import MapieQuantileRegressor\n",
    "\n",
    "from utils.transformations import ExtendedTransformation, SimpleTransformation\n",
    "from utils.filters import SimpleFilter\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:  (20974, 40)\n",
      "bin_vars_columns shape:  (36,)\n",
      "low_card_columns shape:  37\n",
      "X shape:  (20974, 40)\n",
      "X_low_card   shape:  (20974, 113)\n",
      "X_high_card shape:  (20974, 50)\n",
      "X_crossed_features shape:  (20974, 6670)\n",
      "X_EXPANDED shape:  (20974, 6835)\n",
      "(20974, 6835)\n",
      "(20974, 4173)\n",
      "(20974, 3198)\n",
      "(20974, 1630)\n",
      "(20974, 4173)\n",
      "(20974, 3198)\n",
      "(20974, 1630)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"train_data/preprocessed/train_data.csv\")\n",
    "X_train, y_train = df_train.drop(columns=['Price']), df_train[['Price']]\n",
    "preprocessor = ExtendedTransformation()\n",
    "filter = SimpleFilter()\n",
    "preprocessor.fit(X_train, y_train)\n",
    "X_processed, y_processed = preprocessor.transform(X_train, y_train)\n",
    "filter.fit(X_processed, y_processed)\n",
    "X_filtered, y_filtered = filter.transform(X_processed, y_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_test = pd.read_csv(\"train_data/preprocessed/test_data.csv\")\n",
    "X_test, y_test = df_test.drop(columns=['Price']), df_test[['Price']]\n",
    "X_test_proccesed, y_test_proccessed = preprocessor.transform(X_test, y_test)\n",
    "X_test_filtered, y_test_filtered = filter.transform(X_test_proccesed, y_test_proccessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizamos para calcular el quantil medio con mejor precision.\n",
    "\n",
    "import optuna\n",
    "from sklearn.ensemble import GradientBoostingRegressor, HistGradientBoostingRegressor, RandomForestRegressor\n",
    "import sklearn.model_selection\n",
    "from sklearn.metrics import mean_pinball_loss, make_scorer\n",
    "def objective(trial):\n",
    "    x, y = X_filtered, y_filtered.flatten()\n",
    "\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 10, 500, log=True)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 5, 32, log=True)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 0.001, 0.1, log=True)\n",
    "    estimator = HistGradientBoostingRegressor(max_iter=n_estimators, \n",
    "                                              max_depth=max_depth, \n",
    "                                              learning_rate=learning_rate,\n",
    "                                              loss = \"quantile\",\n",
    "                                              quantile = 0.5)\n",
    "\n",
    "    \n",
    "    score = make_scorer(mean_pinball_loss, alpha=0.5)\n",
    "    scoring = sklearn.model_selection.cross_val_score(estimator, x, y, n_jobs=-1, cv=3, scoring=score)\n",
    "\n",
    "    return scoring.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=10)\n",
    "print(study.best_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_params = study.best_trial.params\n",
    "estimator_params['loss'] = \"quantile\"\n",
    "estimator_params['quantile'] = 0.5\n",
    "estimator_params['max_iter'] = estimator_params['n_estimators']\n",
    "del estimator_params['n_estimators']\n",
    "estimator_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = HistGradientBoostingRegressor(**estimator_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.2 # 80% de confianza\n",
    "quantile_params = {\"method\": \"quantile\", \"cv\": \"split\", \"alpha\": alpha}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapie = MapieQuantileRegressor(estimator, **quantile_params)\n",
    "mapie.fit(\n",
    "            X_filtered, \n",
    "            y_filtered,\n",
    "            calib_size=0.3,\n",
    "            random_state=0\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred, y_pis = mapie.predict(X_test_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pis[:,0]\n",
    "preprocessor.inverse_transform(y_pis[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to original scale\n",
    "y_mediam = preprocessor.inverse_transform(y_pred.reshape(-1,1))\n",
    "y_low = preprocessor.inverse_transform(y_pis[:,0])\n",
    "y_high = preprocessor.inverse_transform(y_pis[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluamos su cobertura, para ver si realmente en el 80% de los casos el valor real está dentro del intervalo mostrado.\n",
    "coverage = regression_coverage_score(y_test, y_low, y_high)\n",
    "mean_width = regression_mean_width_score(y_low, y_high)\n",
    "\n",
    "print(f\"regresion coverage: {coverage}\")\n",
    "print(f\"interval mean width: {mean_width}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "CHECKPOINTS_DIR = \"checkpoints\"\n",
    "# Save the objects\n",
    "with open(os.path.join(CHECKPOINTS_DIR, \"preprocessor.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(preprocessor, f)\n",
    "\n",
    "with open(os.path.join(CHECKPOINTS_DIR, \"filter.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(filter, f)\n",
    "\n",
    "with open(os.path.join(CHECKPOINTS_DIR, \"model_with_intervals.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(mapie, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the objects\n",
    "with open(os.path.join(CHECKPOINTS_DIR, \"preprocessor.pkl\"), \"rb\") as f:\n",
    "    my_preprocessor = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(CHECKPOINTS_DIR, \"filter.pkl\"), \"rb\") as f:\n",
    "    my_filter = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(CHECKPOINTS_DIR, \"model_with_intervals.pkl\"), \"rb\") as f:\n",
    "    model_w_intervals = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocesamos\n",
    "X_processed, y_processed = my_preprocessor.transform(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# filtramos\n",
    "X_filtered, y_filtered = my_filter.transform(X_processed, y_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predecimos\n",
    "pred, intervals = model_w_intervals.predict(X_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformamos a la escala adecuada.\n",
    "y_mediam = my_preprocessor.inverse_transform(y_pred.reshape(-1,1))\n",
    "y_low = my_preprocessor.inverse_transform(y_pis[:,0])\n",
    "y_high = my_preprocessor.inverse_transform(y_pis[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluamos su cobertura, para ver si realmente en el 80% de los casos el valor real está dentro del intervalo mostrado.\n",
    "coverage = regression_coverage_score(y_test, y_low, y_high)\n",
    "mean_width = regression_mean_width_score(y_low, y_high)\n",
    "\n",
    "print(f\"regresion coverage: {coverage}\")\n",
    "print(f\"interval mean width: {mean_width}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "m_datos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
